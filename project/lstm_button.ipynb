{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#LSTM 사용하여 버튼 하나의 x좌표 예측\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 99, 3)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7) #결과를 재현할 수 있도록 난수 시드 수정\n",
    "data1=pd.read_excel('x_data.xls') #x좌표 엑셀 데이터 불러옴 \n",
    "data2=pd.read_excel('y_data.xls') #x좌표 엑셀 데이터 불러옴 \n",
    "data3=pd.read_excel('speed.xls') #x좌표 엑셀 데이터 불러옴 \n",
    "\n",
    "pddata1=pd.DataFrame(data1) \n",
    "pddata1.head()\n",
    "pddata2=pd.DataFrame(data2) \n",
    "pddata2.head()\n",
    "pddata3=pd.DataFrame(data3) \n",
    "pddata3.head()\n",
    "\n",
    "hap=[] #진짜 합\n",
    "for j in range(len(pddata1)):\n",
    "    x_data=np.array(pddata1.loc[j])\n",
    "    y_data=np.array(pddata2.loc[j])\n",
    "    s_data=np.array(pddata3.loc[j])\n",
    "\n",
    "    hap1=[] #[x,y,속력] 데이터를 저장하고 있는 리스트\n",
    "\n",
    "    for i in range(len(s_data)): \n",
    "        sum=[] #리스트 하나당 임시로 x,y,속력을 저장할 리스트 (for문 돌릴때마다 초기화)\n",
    "        sum.append(x_data[i]) #x넣음\n",
    "        sum.append(y_data[i]) #y넣음\n",
    "        sum.append(s_data[i]) #속력넣음\n",
    "        hap1.append(sum) #[x,y,속력] 하나의 리스트를 hap리스트에 넣음  \n",
    "\n",
    "    j = j + 1\n",
    "    \n",
    "    hap.append(hap1)\n",
    "\n",
    "n1 = np.array(hap)\n",
    "print(n1.shape) #257,99,3 257개의 샘플과 99개 시계열, 3개 피쳐(x,y,속력)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = n1.shape[0] # 257개 샘플 데이터\n",
    "num_sequence = n1.shape[1] # 99개 시계열 데이터\n",
    "num_feature = n1.shape[2] #3개 피쳐\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler() #클래스의 인스턴스 생성\n",
    "\n",
    "\n",
    "#시계열 선회하면서 피팅함\n",
    "for ss in range(num_sequence):\n",
    "    scaler.partial_fit(n1[:,ss,:])\n",
    "    \n",
    "#Numpy 활용하여 3차원 데이터 스케일링(변환) 0~1 스케일링\n",
    "results=[]\n",
    "for ss in range(num_sequence):\n",
    "    results.append(scaler.transform(n1[:,ss,:]).reshape(num_sample,1,num_feature))\n",
    "n1_scaled = np.concatenate(results, axis=1)\n",
    "\n",
    "dataset=  n1_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        ...,\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ]],\n",
       "\n",
       "       [[0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        ...,\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.01649124]],\n",
       "\n",
       "       [[0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        ...,\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.14511575, 0.12140575, 0.        ],\n",
       "        [0.14511575, 0.12140575, 0.        ],\n",
       "        [0.14511575, 0.12140575, 0.        ],\n",
       "        ...,\n",
       "        [0.03274986, 0.35623003, 0.        ],\n",
       "        [0.03274986, 0.35623003, 0.        ],\n",
       "        [0.03274986, 0.35623003, 0.        ]],\n",
       "\n",
       "       [[0.0299266 , 0.35782748, 0.        ],\n",
       "        [0.0299266 , 0.35782748, 0.        ],\n",
       "        [0.0299266 , 0.35782748, 0.        ],\n",
       "        ...,\n",
       "        [0.01806889, 0.48242812, 0.01649124],\n",
       "        [0.01806889, 0.485623  , 0.        ],\n",
       "        [0.01806889, 0.485623  , 0.        ]],\n",
       "\n",
       "       [[0.01806889, 0.55271565, 0.        ],\n",
       "        [0.01806889, 0.55271565, 0.        ],\n",
       "        [0.01806889, 0.55271565, 0.        ],\n",
       "        ...,\n",
       "        [0.04009034, 0.13738019, 0.07466724],\n",
       "        [0.03952569, 0.12300319, 0.        ],\n",
       "        [0.03952569, 0.12300319, 0.0782248 ]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.67) #학습 데이터 67%\n",
    "test_size = len(dataset) - train_size #테스트 데이터 33%\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "# look_back = 1 #이전 시간 단계 입력변수\n",
    "# #X는 지금 t 값이고, Y는 그 다음의 t+1 값임 (즉, X=t, Y=t+1)\n",
    "# trainX, trainY = create_dataset(train, look_back)\n",
    "# testX, testY = create_dataset(test, look_back)\n",
    "# LSTM 모델은 입력데이터 X에 [samples, time steps, features]형식으로 넣어야함\n",
    "# 현재 데이터는 [samples, features]이므로, numpy.reshape()를 사용하여\n",
    "#준비된 train과 test 입력 데이터를 3차원으로 바꿈\n",
    "# trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "# testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "# # dataframe=pd.DataFrame(hap)\n",
    "# dataframe=pd.DataFrame(data1) #DataFrame은 2차원 테이블 데이터 구조 자료형\n",
    "\n",
    "# dataset = dataframe.values #데이터 프레임에서 numpy배열 추출\n",
    "\n",
    "# dataset = dataset.astype('float32') #정수값을 부동 소수점 값으로 변환\n",
    "# # LSTM 은 S자형(기본값) 또는 tanh활성화 기능을 사용할 떄 입력 데이터의 스케일에 민감\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1)) #정규화함 (0에서 1까지의 범위로 데이터 크기 조정)\n",
    "# dataset = scaler.fit_transform(dataset.reshape(-1,1))\n",
    "#reshape함수를 사용하여 1차원 데이터를 2차원으로 변경\n",
    "\n",
    "# dataset=  n1_scaled\n",
    "\n",
    "# train_size = int(len(dataset) * 0.67) #학습 데이터 67%\n",
    "# test_size = len(dataset) - train_size #테스트 데이터 33%\n",
    "# train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "#두개의 인수, 데이터 세트로 변환하려는 Numpt 배열인 dataset과 다음 시간을 예측하기\n",
    "#위해 입력 변수로 사용할 이전 시간 단계 수인 look_back을 사용. 기본값을 1\n",
    "\n",
    "# look_back = 1 #이전 시간 단계 입력변수\n",
    "# #X는 지금 t 값이고, Y는 그 다음의 t+1 값임 (즉, X=t, Y=t+1)\n",
    "# trainX, trainY = create_dataset(train, look_back)\n",
    "# testX, testY = create_dataset(test, look_back)\n",
    "# # LSTM 모델은 입력데이터 X에 [samples, time steps, features]형식으로 넣어야함\n",
    "# # 현재 데이터는 [samples, features]이므로, numpy.reshape()를 사용하여\n",
    "# #준비된 train과 test 입력 데이터를 3차원으로 바꿈\n",
    "# trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "# testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        ...,\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ]],\n",
       "\n",
       "       [[0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        ...,\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.01649124]],\n",
       "\n",
       "       [[0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        ...,\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.10333145, 0.63258786, 0.        ],\n",
       "        [0.10333145, 0.63258786, 0.        ],\n",
       "        [0.10333145, 0.63258786, 0.        ],\n",
       "        ...,\n",
       "        [0.05194805, 0.57667732, 0.        ],\n",
       "        [0.05194805, 0.57667732, 0.01843776],\n",
       "        [0.05081875, 0.57507987, 0.        ]],\n",
       "\n",
       "       [[0.04968944, 0.56709265, 0.        ],\n",
       "        [0.04968944, 0.56709265, 0.02332213],\n",
       "        [0.04856014, 0.56389776, 0.        ],\n",
       "        ...,\n",
       "        [0.0107284 , 0.37539936, 0.        ],\n",
       "        [0.0107284 , 0.37539936, 0.        ],\n",
       "        [0.0107284 , 0.37539936, 0.        ]],\n",
       "\n",
       "       [[0.02823264, 0.29872204, 0.        ],\n",
       "        [0.02823264, 0.29872204, 0.        ],\n",
       "        [0.02823264, 0.29872204, 0.        ],\n",
       "        ...,\n",
       "        [0.07905138, 0.12619808, 0.0480798 ],\n",
       "        [0.08187465, 0.12140575, 0.        ],\n",
       "        [0.08187465, 0.12140575, 0.02332213]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10446076, 0.08466454, 0.        ],\n",
       "        [0.10446076, 0.08466454, 0.        ],\n",
       "        [0.10446076, 0.08466454, 0.        ],\n",
       "        ...,\n",
       "        [0.19649915, 0.28913738, 0.08489383],\n",
       "        [0.20158103, 0.2971246 , 0.        ],\n",
       "        [0.20158103, 0.2971246 , 0.07093148]],\n",
       "\n",
       "       [[0.24957651, 0.45047923, 0.        ],\n",
       "        [0.24957651, 0.45047923, 0.        ],\n",
       "        [0.24957651, 0.45047923, 0.        ],\n",
       "        ...,\n",
       "        [0.12704687, 0.36102236, 0.05214986],\n",
       "        [0.12365895, 0.35782748, 0.        ],\n",
       "        [0.12365895, 0.35782748, 0.02332213]],\n",
       "\n",
       "       [[0.12027103, 0.34824281, 0.        ],\n",
       "        [0.12027103, 0.34824281, 0.        ],\n",
       "        [0.12027103, 0.34824281, 0.        ],\n",
       "        ...,\n",
       "        [0.0920384 , 0.26996805, 0.        ],\n",
       "        [0.0920384 , 0.26996805, 0.077789  ],\n",
       "        [0.08752117, 0.26198083, 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.14511575, 0.12140575, 0.        ],\n",
       "        [0.14511575, 0.12140575, 0.        ],\n",
       "        [0.14511575, 0.12140575, 0.        ],\n",
       "        ...,\n",
       "        [0.03274986, 0.35623003, 0.        ],\n",
       "        [0.03274986, 0.35623003, 0.        ],\n",
       "        [0.03274986, 0.35623003, 0.        ]],\n",
       "\n",
       "       [[0.0299266 , 0.35782748, 0.        ],\n",
       "        [0.0299266 , 0.35782748, 0.        ],\n",
       "        [0.0299266 , 0.35782748, 0.        ],\n",
       "        ...,\n",
       "        [0.01806889, 0.48242812, 0.01649124],\n",
       "        [0.01806889, 0.485623  , 0.        ],\n",
       "        [0.01806889, 0.485623  , 0.        ]],\n",
       "\n",
       "       [[0.01806889, 0.55271565, 0.        ],\n",
       "        [0.01806889, 0.55271565, 0.        ],\n",
       "        [0.01806889, 0.55271565, 0.        ],\n",
       "        ...,\n",
       "        [0.04009034, 0.13738019, 0.07466724],\n",
       "        [0.03952569, 0.12300319, 0.        ],\n",
       "        [0.03952569, 0.12300319, 0.0782248 ]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 99, 3)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 99, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#배열을 행렬로 변한\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [],[] \n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back):]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i:(i + look_back):])\n",
    "    \n",
    "    dataX=np.squeeze(dataX,axis=1) #차원 축소\n",
    "    dataY=np.squeeze(dataY,axis=1) #차원 축소\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#두개의 인수, 데이터 세트로 변환하려는 Numpy 배열인 dataset과 다음 시간을 예측하기\n",
    "#위해 입력 변수로 사용할 이전 시간 단계 수인 look_back을 사용. 기본값을 1\n",
    "#reshpae()함수를 사용하여 배열의 차원을 변경할 수 있음\n",
    "\n",
    "look_back = 1 #이전 시간 단계 입력변수\n",
    "#X는 지금 t 값이고, Y는 그 다음의 t+1 값임 (즉, X=t, Y=t+1)\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)\n",
    "# LSTM 모델은 입력데이터 X에 [samples, time steps, features]형식으로 넣어야함\n",
    "# 현재 데이터는 [samples, features]이므로, numpy.reshape()를 사용하여\n",
    "#준비된 train과 test 입력 데이터를 3차원으로 바꿈\n",
    "# trainX = np.reshape(trainX.shape[0], trainX.shape[1], trainX.shape[2])\n",
    "# testX = np.reshape(testX.shape[0], testX.shape[1], testX.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 99, 3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 99, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        ...,\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ]],\n",
       "\n",
       "       [[0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        ...,\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.01649124]],\n",
       "\n",
       "       [[0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        ...,\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.10333145, 0.63258786, 0.        ],\n",
       "        [0.10333145, 0.63258786, 0.        ],\n",
       "        [0.10333145, 0.63258786, 0.        ],\n",
       "        ...,\n",
       "        [0.05194805, 0.57667732, 0.        ],\n",
       "        [0.05194805, 0.57667732, 0.01843776],\n",
       "        [0.05081875, 0.57507987, 0.        ]],\n",
       "\n",
       "       [[0.04968944, 0.56709265, 0.        ],\n",
       "        [0.04968944, 0.56709265, 0.02332213],\n",
       "        [0.04856014, 0.56389776, 0.        ],\n",
       "        ...,\n",
       "        [0.0107284 , 0.37539936, 0.        ],\n",
       "        [0.0107284 , 0.37539936, 0.        ],\n",
       "        [0.0107284 , 0.37539936, 0.        ]],\n",
       "\n",
       "       [[0.02823264, 0.29872204, 0.        ],\n",
       "        [0.02823264, 0.29872204, 0.        ],\n",
       "        [0.02823264, 0.29872204, 0.        ],\n",
       "        ...,\n",
       "        [0.07905138, 0.12619808, 0.0480798 ],\n",
       "        [0.08187465, 0.12140575, 0.        ],\n",
       "        [0.08187465, 0.12140575, 0.02332213]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        [0.13551666, 0.08466454, 0.        ],\n",
       "        ...,\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ],\n",
       "        [0.04291361, 0.25239617, 0.        ]],\n",
       "\n",
       "       [[0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        [0.03500847, 0.27476038, 0.        ],\n",
       "        ...,\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.        ],\n",
       "        [0.10559006, 0.36261981, 0.01649124]],\n",
       "\n",
       "       [[0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        [0.23433089, 0.20607029, 0.        ],\n",
       "        ...,\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ],\n",
       "        [0.14624506, 0.37380192, 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.23094297, 0.19329073, 0.        ],\n",
       "        [0.23094297, 0.19329073, 0.        ],\n",
       "        [0.23094297, 0.19329073, 0.        ],\n",
       "        ...,\n",
       "        [0.15471485, 0.39297125, 0.        ],\n",
       "        [0.15471485, 0.39297125, 0.        ],\n",
       "        [0.15471485, 0.39297125, 0.        ]],\n",
       "\n",
       "       [[0.13664596, 0.42172524, 0.        ],\n",
       "        [0.13664596, 0.42172524, 0.        ],\n",
       "        [0.13664596, 0.42172524, 0.        ],\n",
       "        ...,\n",
       "        [0.10446076, 0.57348243, 0.03399755],\n",
       "        [0.1038961 , 0.5798722 , 0.        ],\n",
       "        [0.1038961 , 0.5798722 , 0.02473685]],\n",
       "\n",
       "       [[0.10333145, 0.63258786, 0.        ],\n",
       "        [0.10333145, 0.63258786, 0.        ],\n",
       "        [0.10333145, 0.63258786, 0.        ],\n",
       "        ...,\n",
       "        [0.05194805, 0.57667732, 0.        ],\n",
       "        [0.05194805, 0.57667732, 0.01843776],\n",
       "        [0.05081875, 0.57507987, 0.        ]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_36 (LSTM)               (None, 99, 32)            4608      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 99, 3)             99        \n",
      "=================================================================\n",
      "Total params: 4,707\n",
      "Trainable params: 4,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#LSTM 모델 생성\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers import Reshape\n",
    "\n",
    "model = Sequential() # Sequeatial Model \n",
    "\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=trainX.shape[-2:]))  \n",
    "# 20: 메모리 셀의 개수 input_shape: (timestep, feature) \n",
    "\n",
    "model.add(Dense(3)) # 3개의 예측\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam') \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "170/170 [==============================] - 1s 6ms/step - loss: 0.0717\n",
      "Epoch 2/5\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.0424\n",
      "Epoch 3/5\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.0204\n",
      "Epoch 4/5\n",
      "170/170 [==============================] - 0s 2ms/step - loss: 0.0090\n",
      "Epoch 5/5\n",
      "170/170 [==============================] - 0s 3ms/step - loss: 0.0079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2605efd0548>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=5,batch_size=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-153-dc9bad41196b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#inverse_trasform()함수를 사용하여 스케일링된 결과 값을 본래 값으로 구함\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtrainPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainPredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mtrainY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtestPredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestPredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[1;32m--> 434\u001b[1;33m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 574\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "\n",
    "# nsamples, nx, ny=trainX.shape\n",
    "# trainX=trainX.reshape((nsamples,nx*ny))\n",
    "# nsamples, nx, ny=testX.shape\n",
    "# testX=testX.reshape((nsamples,nx*ny))\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "#inverse_trasform()함수를 사용하여 스케일링된 결과 값을 본래 값으로 구함\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY]) \n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#원래 데이터셋 : 파란색, 테스트 데이터셋 : 녹색 #훈련 데이터셋 : 주황색\n",
    "#train 예측 \n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "plt.plot(scaler.inverse_transform(dataset)) #전체 데이터\n",
    "plt.show()\n",
    "plt.plot(trainPredictPlot) #초반 부분 train 데이터\n",
    "plt.show()\n",
    "plt.plot(testPredictPlot) #후반 부분 test 데이터\n",
    "plt.show()\n",
    "\n",
    "plt.plot(scaler.inverse_transform(dataset)) #전체 데이터\n",
    "plt.plot(trainPredictPlot) #초반 부분 train 데이터\n",
    "plt.plot(testPredictPlot) #후반 부분 test 데이터\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
