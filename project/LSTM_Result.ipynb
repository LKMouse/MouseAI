{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# LSTM for international airline passengers problem with memory\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [],[] \n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back):]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i:(i + look_back):])\n",
    "    \n",
    "    dataX=np.squeeze(dataX,axis=1) #차원 축소\n",
    "    dataY=np.squeeze(dataY,axis=1) #차원 축소\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257, 99, 3)\n"
     ]
    }
   ],
   "source": [
    "data1=pd.read_excel('x_data.xls') #x좌표 엑셀 데이터 불러옴 \n",
    "data2=pd.read_excel('y_data.xls') #y좌표 엑셀 데이터 불러옴 \n",
    "data3=pd.read_excel('speed.xls') #speed좌표 엑셀 데이터 불러옴 \n",
    "\n",
    "pddata1=pd.DataFrame(data1) \n",
    "pddata1.head()\n",
    "pddata2=pd.DataFrame(data2) \n",
    "pddata2.head()\n",
    "pddata3=pd.DataFrame(data3) \n",
    "pddata3.head()\n",
    "\n",
    "hap=[] #진짜 합\n",
    "for j in range(len(pddata1)):\n",
    "    x_data=np.array(pddata1.loc[j])\n",
    "    y_data=np.array(pddata2.loc[j])\n",
    "    s_data=np.array(pddata3.loc[j])\n",
    "\n",
    "    hap1=[] #[x,y,속력] 데이터를 저장하고 있는 리스트\n",
    "    \n",
    "    for i in range(len(s_data)): \n",
    "        sum=[] #리스트 하나당 임시로 x,y,속력을 저장할 리스트 (for문 돌릴때마다 초기화)\n",
    "        sum.append(x_data[i]) #x넣음\n",
    "        sum.append(y_data[i]) #y넣음\n",
    "        sum.append(s_data[i]) #속력넣음\n",
    "        hap1.append(sum) #[x,y,속력] 하나의 리스트를 hap리스트에 넣음  \n",
    "\n",
    "    j = j + 1\n",
    "    \n",
    "    hap.append(hap1)\n",
    "\n",
    "n1 = np.array(hap)\n",
    "print(n1.shape) #257,99,3 257개의 Sample과 99개 시계열, 3개 feature(x,y,속력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = n1.shape[0] # 257개 Sample 데이터\n",
    "num_sequence = n1.shape[1] # 99개 시계열 데이터\n",
    "num_feature = n1.shape[2] #3개 Feature\n",
    "\n",
    "dataset = n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[388.        , 252.        ,   0.        ],\n",
       "        [388.        , 252.        ,   0.        ],\n",
       "        [388.        , 252.        ,   0.        ],\n",
       "        ...,\n",
       "        [224.        , 357.        ,   0.        ],\n",
       "        [224.        , 357.        ,   0.        ],\n",
       "        [224.        , 357.        ,   0.        ]],\n",
       "\n",
       "       [[210.        , 371.        ,   0.        ],\n",
       "        [210.        , 371.        ,   0.        ],\n",
       "        [210.        , 371.        ,   0.        ],\n",
       "        ...,\n",
       "        [335.        , 426.        ,   0.        ],\n",
       "        [335.        , 426.        ,   0.        ],\n",
       "        [335.        , 426.        ,   2.        ]],\n",
       "\n",
       "       [[563.        , 328.        ,   0.        ],\n",
       "        [563.        , 328.        ,   0.        ],\n",
       "        [563.        , 328.        ,   0.        ],\n",
       "        ...,\n",
       "        [407.        , 433.        ,   0.        ],\n",
       "        [407.        , 433.        ,   0.        ],\n",
       "        [407.        , 433.        ,   0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[405.        , 275.        ,   0.        ],\n",
       "        [405.        , 275.        ,   0.        ],\n",
       "        [405.        , 275.        ,   0.        ],\n",
       "        ...,\n",
       "        [206.        , 422.        ,   0.        ],\n",
       "        [206.        , 422.        ,   0.        ],\n",
       "        [206.        , 422.        ,   0.        ]],\n",
       "\n",
       "       [[201.        , 423.        ,   0.        ],\n",
       "        [201.        , 423.        ,   0.        ],\n",
       "        [201.        , 423.        ,   0.        ],\n",
       "        ...,\n",
       "        [180.        , 501.        ,   2.        ],\n",
       "        [180.        , 503.        ,   0.        ],\n",
       "        [180.        , 503.        ,   0.        ]],\n",
       "\n",
       "       [[180.        , 545.        ,   0.        ],\n",
       "        [180.        , 545.        ,   0.        ],\n",
       "        [180.        , 545.        ,   0.        ],\n",
       "        ...,\n",
       "        [219.        , 285.        ,   9.05538514],\n",
       "        [218.        , 276.        ,   0.        ],\n",
       "        [218.        , 276.        ,   9.48683298]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.70) #학습 데이터 70%\n",
    "test_size = len(dataset) - train_size #테스트 데이터 30%\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[388.        , 252.        ,   0.        ],\n",
       "        [388.        , 252.        ,   0.        ],\n",
       "        [388.        , 252.        ,   0.        ],\n",
       "        ...,\n",
       "        [224.        , 357.        ,   0.        ],\n",
       "        [224.        , 357.        ,   0.        ],\n",
       "        [224.        , 357.        ,   0.        ]],\n",
       "\n",
       "       [[210.        , 371.        ,   0.        ],\n",
       "        [210.        , 371.        ,   0.        ],\n",
       "        [210.        , 371.        ,   0.        ],\n",
       "        ...,\n",
       "        [335.        , 426.        ,   0.        ],\n",
       "        [335.        , 426.        ,   0.        ],\n",
       "        [335.        , 426.        ,   2.        ]],\n",
       "\n",
       "       [[563.        , 328.        ,   0.        ],\n",
       "        [563.        , 328.        ,   0.        ],\n",
       "        [563.        , 328.        ,   0.        ],\n",
       "        ...,\n",
       "        [407.        , 433.        ,   0.        ],\n",
       "        [407.        , 433.        ,   0.        ],\n",
       "        [407.        , 433.        ,   0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[379.        , 280.        ,   0.        ],\n",
       "        [379.        , 280.        ,   0.        ],\n",
       "        [379.        , 280.        ,   0.        ],\n",
       "        ...,\n",
       "        [196.        , 391.        ,   0.        ],\n",
       "        [196.        , 391.        ,   2.82842712],\n",
       "        [194.        , 393.        ,   0.        ]],\n",
       "\n",
       "       [[189.        , 400.        ,   0.        ],\n",
       "        [189.        , 400.        ,   0.        ],\n",
       "        [189.        , 400.        ,   0.        ],\n",
       "        ...,\n",
       "        [192.        , 497.        ,   0.        ],\n",
       "        [192.        , 497.        ,   2.        ],\n",
       "        [192.        , 499.        ,   0.        ]],\n",
       "\n",
       "       [[192.        , 528.        ,   0.        ],\n",
       "        [192.        , 528.        ,   0.        ],\n",
       "        [192.        , 528.        ,   0.        ],\n",
       "        ...,\n",
       "        [379.        , 469.        ,   0.        ],\n",
       "        [379.        , 469.        ,   0.        ],\n",
       "        [379.        , 469.        ,   0.        ]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[383.        , 461.        ,   0.        ],\n",
       "        [383.        , 461.        ,   0.        ],\n",
       "        [383.        , 461.        ,   0.        ],\n",
       "        ...,\n",
       "        [414.        , 396.        ,   0.        ],\n",
       "        [414.        , 396.        ,   4.24264069],\n",
       "        [417.        , 393.        ,   0.        ]],\n",
       "\n",
       "       [[511.        , 314.        ,   0.        ],\n",
       "        [511.        , 314.        ,   0.        ],\n",
       "        [511.        , 314.        ,   0.        ],\n",
       "        ...,\n",
       "        [531.        , 443.        ,   0.        ],\n",
       "        [531.        , 443.        ,   1.41421356],\n",
       "        [532.        , 444.        ,   0.        ]],\n",
       "\n",
       "       [[534.        , 456.        ,   0.        ],\n",
       "        [534.        , 456.        ,   0.        ],\n",
       "        [534.        , 456.        ,   0.        ],\n",
       "        ...,\n",
       "        [424.        , 532.        ,   0.        ],\n",
       "        [424.        , 532.        ,   0.        ],\n",
       "        [424.        , 532.        ,   2.82842712]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[405.        , 275.        ,   0.        ],\n",
       "        [405.        , 275.        ,   0.        ],\n",
       "        [405.        , 275.        ,   0.        ],\n",
       "        ...,\n",
       "        [206.        , 422.        ,   0.        ],\n",
       "        [206.        , 422.        ,   0.        ],\n",
       "        [206.        , 422.        ,   0.        ]],\n",
       "\n",
       "       [[201.        , 423.        ,   0.        ],\n",
       "        [201.        , 423.        ,   0.        ],\n",
       "        [201.        , 423.        ,   0.        ],\n",
       "        ...,\n",
       "        [180.        , 501.        ,   2.        ],\n",
       "        [180.        , 503.        ,   0.        ],\n",
       "        [180.        , 503.        ,   0.        ]],\n",
       "\n",
       "       [[180.        , 545.        ,   0.        ],\n",
       "        [180.        , 545.        ,   0.        ],\n",
       "        [180.        , 545.        ,   0.        ],\n",
       "        ...,\n",
       "        [219.        , 285.        ,   9.05538514],\n",
       "        [218.        , 276.        ,   0.        ],\n",
       "        [218.        , 276.        ,   9.48683298]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 99, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179, 99, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78, 99, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 1 #이전 시간 단계 입력변수\n",
    "#X는 지금 t 값이고, Y는 그 다음의 t+1 값임 (즉, X=t, Y=t+1)\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 99, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 99, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177, 99, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 99, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 141 samples, validate on 36 samples\n",
      "Epoch 1/150\n",
      "141/141 [==============================] - 3s 18ms/step - loss: 117131.0363 - val_loss: 112812.8602\n",
      "Epoch 2/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117131.7835 - val_loss: 112816.2769\n",
      "Epoch 3/150\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 117132.8364 - val_loss: 112812.9631\n",
      "Epoch 4/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117116.6319 - val_loss: 112792.4353\n",
      "Epoch 5/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117109.2666 - val_loss: 112791.1732\n",
      "Epoch 6/150\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 117108.8338 - val_loss: 112792.4197\n",
      "Epoch 7/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117108.3018 - val_loss: 112791.6623\n",
      "Epoch 8/150\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 117107.9881 - val_loss: 112790.2214\n",
      "Epoch 9/150\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 117107.8543 - val_loss: 112791.9570\n",
      "Epoch 10/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117108.8387 - val_loss: 112791.9518\n",
      "Epoch 11/150\n",
      "141/141 [==============================] - 1s 10ms/step - loss: 117109.1747 - val_loss: 112792.7695\n",
      "Epoch 12/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117108.3331 - val_loss: 112790.8251\n",
      "Epoch 13/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117107.2367 - val_loss: 112789.9332\n",
      "Epoch 14/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117106.4554 - val_loss: 112790.1063\n",
      "Epoch 15/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.9186 - val_loss: 112790.0408\n",
      "Epoch 16/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.8952 - val_loss: 112790.1463\n",
      "Epoch 17/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.8725 - val_loss: 112789.8125\n",
      "Epoch 18/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117104.6690 - val_loss: 112788.0234\n",
      "Epoch 19/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117104.0639 - val_loss: 112788.7231\n",
      "Epoch 20/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.7699 - val_loss: 112790.9240\n",
      "Epoch 21/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.4469 - val_loss: 112789.5894\n",
      "Epoch 22/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.8705 - val_loss: 112789.6124\n",
      "Epoch 23/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.1516 - val_loss: 112790.0964\n",
      "Epoch 24/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117107.0406 - val_loss: 112791.9293\n",
      "Epoch 25/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117107.2591 - val_loss: 112790.8620\n",
      "Epoch 26/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.1384 - val_loss: 112790.3494\n",
      "Epoch 27/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.7749 - val_loss: 112789.7253\n",
      "Epoch 28/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117108.2309 - val_loss: 112792.7574\n",
      "Epoch 29/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117112.1995 - val_loss: 112794.6037\n",
      "Epoch 30/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117116.3358 - val_loss: 112794.9475\n",
      "Epoch 31/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117114.4706 - val_loss: 112794.8003\n",
      "Epoch 32/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117112.6640 - val_loss: 112791.8581\n",
      "Epoch 33/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117110.9141 - val_loss: 112791.5534\n",
      "Epoch 34/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117109.1114 - val_loss: 112790.7513\n",
      "Epoch 35/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117108.2179 - val_loss: 112790.2070\n",
      "Epoch 36/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117108.9623 - val_loss: 112790.6259\n",
      "Epoch 37/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117107.4702 - val_loss: 112790.5951\n",
      "Epoch 38/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117109.4511 - val_loss: 112791.1923\n",
      "Epoch 39/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117108.4412 - val_loss: 112790.2543\n",
      "Epoch 40/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.3031 - val_loss: 112789.9848\n",
      "Epoch 41/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117106.1666 - val_loss: 112789.4214\n",
      "Epoch 42/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.8824 - val_loss: 112789.8442\n",
      "Epoch 43/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.8357 - val_loss: 112789.8234\n",
      "Epoch 44/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.8332 - val_loss: 112789.7535\n",
      "Epoch 45/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.8187 - val_loss: 112789.7639\n",
      "Epoch 46/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.8260 - val_loss: 112789.7691\n",
      "Epoch 47/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.7742 - val_loss: 112789.7743\n",
      "Epoch 48/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.7340 - val_loss: 112789.7135\n",
      "Epoch 49/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.7335 - val_loss: 112789.7643\n",
      "Epoch 50/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.7588 - val_loss: 112789.6688\n",
      "Epoch 51/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.7154 - val_loss: 112789.6962\n",
      "Epoch 52/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.6734 - val_loss: 112789.7374\n",
      "Epoch 53/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.7066 - val_loss: 112789.0981\n",
      "Epoch 54/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.6792 - val_loss: 112789.6272\n",
      "Epoch 55/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6511 - val_loss: 112789.5933\n",
      "Epoch 56/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6480 - val_loss: 112789.6202\n",
      "Epoch 57/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6406 - val_loss: 112789.6254\n",
      "Epoch 58/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.6802 - val_loss: 112789.0764\n",
      "Epoch 59/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6039 - val_loss: 112788.9961\n",
      "Epoch 60/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6034 - val_loss: 112789.1415\n",
      "Epoch 61/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6147 - val_loss: 112789.1675\n",
      "Epoch 62/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6320 - val_loss: 112789.6059\n",
      "Epoch 63/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6316 - val_loss: 112789.6124\n",
      "Epoch 64/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.6316 - val_loss: 112789.0751\n",
      "Epoch 65/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.9300 - val_loss: 112789.1068\n",
      "Epoch 66/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.0922 - val_loss: 112789.1901\n",
      "Epoch 67/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117106.4786 - val_loss: 112789.3472\n",
      "Epoch 68/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117106.1787 - val_loss: 112789.2266\n",
      "Epoch 69/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.9203 - val_loss: 112789.5499\n",
      "Epoch 70/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.7476 - val_loss: 112789.5872\n",
      "Epoch 71/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.6440 - val_loss: 112789.5764\n",
      "Epoch 72/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.7119 - val_loss: 112789.5599\n",
      "Epoch 73/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.7220 - val_loss: 112789.5404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.6329 - val_loss: 112789.5195\n",
      "Epoch 75/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.6058 - val_loss: 112789.4944\n",
      "Epoch 76/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.5870 - val_loss: 112789.4692\n",
      "Epoch 77/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.6417 - val_loss: 112789.4440\n",
      "Epoch 78/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.5999 - val_loss: 112789.4145\n",
      "Epoch 79/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.5330 - val_loss: 112789.3893\n",
      "Epoch 80/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.5624 - val_loss: 112788.9627\n",
      "Epoch 81/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.5177 - val_loss: 112788.8941\n",
      "Epoch 82/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.5030 - val_loss: 112788.8589\n",
      "Epoch 83/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.4777 - val_loss: 112788.8273\n",
      "Epoch 84/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.4997 - val_loss: 112788.7977\n",
      "Epoch 85/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.4528 - val_loss: 112788.7756\n",
      "Epoch 86/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.4356 - val_loss: 112788.7439\n",
      "Epoch 87/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.4214 - val_loss: 112788.7261\n",
      "Epoch 88/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.4295 - val_loss: 112788.7148\n",
      "Epoch 89/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.4126 - val_loss: 112788.8559\n",
      "Epoch 90/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.4023 - val_loss: 112789.0673\n",
      "Epoch 91/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.3831 - val_loss: 112789.0304\n",
      "Epoch 92/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.4115 - val_loss: 112789.0577\n",
      "Epoch 93/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.2740 - val_loss: 112788.9436\n",
      "Epoch 94/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.2708 - val_loss: 112788.9219\n",
      "Epoch 95/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.2621 - val_loss: 112788.8780\n",
      "Epoch 96/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.2491 - val_loss: 112788.8464\n",
      "Epoch 97/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.3184 - val_loss: 112788.8550\n",
      "Epoch 98/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.2042 - val_loss: 112788.8368\n",
      "Epoch 99/150\n",
      "141/141 [==============================] - 1s 6ms/step - loss: 117105.1581 - val_loss: 112788.7960\n",
      "Epoch 100/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.1035 - val_loss: 112788.8533\n",
      "Epoch 101/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.1374 - val_loss: 112788.7478\n",
      "Epoch 102/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.0634 - val_loss: 112788.7565\n",
      "Epoch 103/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.0637 - val_loss: 112788.7153\n",
      "Epoch 104/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.1371 - val_loss: 112788.6949\n",
      "Epoch 105/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.1366 - val_loss: 112788.6610\n",
      "Epoch 106/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.1023 - val_loss: 112788.6359\n",
      "Epoch 107/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117105.0406 - val_loss: 112788.6042\n",
      "Epoch 108/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117105.0395 - val_loss: 112788.5677\n",
      "Epoch 109/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117105.0267 - val_loss: 112788.5477\n",
      "Epoch 110/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117104.9844 - val_loss: 112788.5174\n",
      "Epoch 111/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117104.9298 - val_loss: 112788.4588\n",
      "Epoch 112/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117104.8406 - val_loss: 112788.3711\n",
      "Epoch 113/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117104.7126 - val_loss: 112788.2695\n",
      "Epoch 114/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117104.4727 - val_loss: 112788.1020\n",
      "Epoch 115/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.9678 - val_loss: 112788.0035\n",
      "Epoch 116/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117103.6478 - val_loss: 112787.8919\n",
      "Epoch 117/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.5560 - val_loss: 112787.7049\n",
      "Epoch 118/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.4723 - val_loss: 112787.7227\n",
      "Epoch 119/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.5281 - val_loss: 112787.6094\n",
      "Epoch 120/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.4447 - val_loss: 112787.5443\n",
      "Epoch 121/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3436 - val_loss: 112787.5291\n",
      "Epoch 122/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3379 - val_loss: 112787.5226\n",
      "Epoch 123/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3221 - val_loss: 112787.5213\n",
      "Epoch 124/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3190 - val_loss: 112787.5204\n",
      "Epoch 125/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117103.3165 - val_loss: 112787.5191\n",
      "Epoch 126/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3243 - val_loss: 112787.5169\n",
      "Epoch 127/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3136 - val_loss: 112787.5156\n",
      "Epoch 128/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117103.3179 - val_loss: 112787.5135\n",
      "Epoch 129/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3343 - val_loss: 112787.5135\n",
      "Epoch 130/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3167 - val_loss: 112787.5156\n",
      "Epoch 131/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3096 - val_loss: 112787.5135\n",
      "Epoch 132/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3124 - val_loss: 112787.5113\n",
      "Epoch 133/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3237 - val_loss: 112787.5113\n",
      "Epoch 134/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3116 - val_loss: 112787.5113\n",
      "Epoch 135/150\n",
      "141/141 [==============================] - ETA: 0s - loss: 117522.11 - 1s 7ms/step - loss: 117103.3032 - val_loss: 112787.5113\n",
      "Epoch 136/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3150 - val_loss: 112787.5113\n",
      "Epoch 137/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3120 - val_loss: 112787.5113\n",
      "Epoch 138/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3200 - val_loss: 112787.5078\n",
      "Epoch 139/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117103.3046 - val_loss: 112787.5078\n",
      "Epoch 140/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3075 - val_loss: 112787.5078\n",
      "Epoch 141/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3126 - val_loss: 112787.5078\n",
      "Epoch 142/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3008 - val_loss: 112787.5078\n",
      "Epoch 143/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3056 - val_loss: 112787.5078\n",
      "Epoch 144/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3073 - val_loss: 112787.5078\n",
      "Epoch 145/150\n",
      "141/141 [==============================] - 1s 9ms/step - loss: 117103.3077 - val_loss: 112787.5078\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3088 - val_loss: 112787.5078\n",
      "Epoch 147/150\n",
      "141/141 [==============================] - 1s 7ms/step - loss: 117103.3103 - val_loss: 112787.5078\n",
      "Epoch 148/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3043 - val_loss: 112787.5078\n",
      "Epoch 149/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3025 - val_loss: 112787.5078\n",
      "Epoch 150/150\n",
      "141/141 [==============================] - 1s 8ms/step - loss: 117103.3136 - val_loss: 112787.5078\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 99, 32)            4608      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 99, 3)             99        \n",
      "=================================================================\n",
      "Total params: 4,707\n",
      "Trainable params: 4,707\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.utils import *\n",
    "\n",
    "model = Sequential() # Sequeatial Model \n",
    "\n",
    "model.add(LSTM(32, activation='relu',return_sequences=True, input_shape=(num_sequence,num_feature)))  \n",
    "# 20: 메모리 셀의 개수 input_shape: (timestep, feature) \n",
    "model.add(Dense(3, activation='softmax')) # 3개의 예측\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam') \n",
    "\n",
    "model.fit(trainX, trainY, epochs=150,batch_size=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 1ms/step\n",
      "정확도:  118583.39761513157\n",
      "y:  [[[383.         461.           0.        ]\n",
      "  [383.         461.           0.        ]\n",
      "  [383.         461.           0.        ]\n",
      "  ...\n",
      "  [414.         396.           0.        ]\n",
      "  [414.         396.           4.24264069]\n",
      "  [417.         393.           0.        ]]\n",
      "\n",
      " [[511.         314.           0.        ]\n",
      "  [511.         314.           0.        ]\n",
      "  [511.         314.           0.        ]\n",
      "  ...\n",
      "  [531.         443.           0.        ]\n",
      "  [531.         443.           1.41421356]\n",
      "  [532.         444.           0.        ]]\n",
      "\n",
      " [[534.         456.           0.        ]\n",
      "  [534.         456.           0.        ]\n",
      "  [534.         456.           0.        ]\n",
      "  ...\n",
      "  [424.         532.           0.        ]\n",
      "  [424.         532.           0.        ]\n",
      "  [424.         532.           2.82842712]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[514.         637.           0.        ]\n",
      "  [514.         637.           0.        ]\n",
      "  [514.         637.           0.        ]\n",
      "  ...\n",
      "  [523.         517.           0.        ]\n",
      "  [523.         517.           0.        ]\n",
      "  [523.         517.           0.        ]]\n",
      "\n",
      " [[526.         508.           0.        ]\n",
      "  [526.         508.           0.        ]\n",
      "  [526.         508.           1.        ]\n",
      "  ...\n",
      "  [503.         373.           0.        ]\n",
      "  [503.         373.           6.32455532]\n",
      "  [501.         367.           0.        ]]\n",
      "\n",
      " [[405.         275.           0.        ]\n",
      "  [405.         275.           0.        ]\n",
      "  [405.         275.           0.        ]\n",
      "  ...\n",
      "  [206.         422.           0.        ]\n",
      "  [206.         422.           0.        ]\n",
      "  [206.         422.           0.        ]]] , predict:  [1.0000000e+00 7.9679438e-18 1.1949103e-28 ... 0.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도: \",(model.evaluate(testX, testY)))\n",
    "\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "print('y: ',testY,', predict: ',model.predict(trainX).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
